title: Log_2015-11-12 -- Atom editor,Git pull
date: 2015-11-15
category: Journal
---
### Linux user view remote display of Windows
1. **Server Port:** Open remote display server on Windows
Computer -> Property -> Manager ->Server -> Open all Remote Desktop server and add to auto launch

2. **Client Port:** Installing `rdesktop` on Linux
```bash
emerge rdesktop
```
3. Launch `rdesktop`
```bash
rdesktop 10.10.64.74 -u username -p password -g 1400x900 # Middle of which is character 'x', not symbol '*'
```
### ArrayWritable example
```java
import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.ArrayWritable;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCount {

    public static class MyMapper extends Mapper<Object, Text, Text, IntWritable> {

        // Initialize Variables
        private final static IntWritable one = new IntWritable(1);
        private Text word = new Text();

        // Map Method
        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {

            // Use Tokenizer
            StringTokenizer itr = new StringTokenizer(value.toString());

            // Select each word
            while (itr.hasMoreTokens()) {
                word.set(itr.nextToken());

                // Output Pair
                context.write(word, one);
            }
        }
    }

    public static class MyReducer
            extends Reducer<Text, IntWritable, Text, IntArrayWritable> {

        // Initialize Variables
        private IntWritable count = new IntWritable();
        private IntWritable length = new IntWritable();

        public void reduce(Text key, Iterable<IntWritable> values,
                           Context context) throws IOException, InterruptedException {

            // Count Words
            int sum = 0;
            for (IntWritable val : values) {
                sum += val.get();
            }

            count.set(sum);

            // Wordlength
            length.set(key.getLength());

            // Define Output
            IntWritable[] temp = new IntWritable[2];
            temp[0] = count;
            temp[1] = length;

            context.write(key, new IntArrayWritable(temp));
        }
    }

    public static class IntArrayWritable extends ArrayWritable {

        public IntArrayWritable(IntWritable[] values) {
            super(IntWritable.class, values);
        }

        @Override
        public IntWritable[] get() {
            return (IntWritable[]) super.get();
        }

        @Override
        public String toString() {
            IntWritable[] values = get();
            return values[0].toString() + ", " + values[1].toString();
        }
    }

    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, "word length V1");

        // Set Classes
        //job.setJarByClass(WordLength_V01.class);
        job.setMapperClass(MyMapper.class);
        // job.setCombinerClass(MyReducer.class);
        job.setReducerClass(MyReducer.class);

        // Set Output and Input Parameters
        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(IntWritable.class);

        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntArrayWritable.class);

        // Number of Reducers
        job.setNumReduceTasks(1);

        // Set FileDestination
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));

        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}
```
```java
import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.ArrayWritable;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCount {

    public static class StateNumMapper
            extends Mapper<Object, Text, IntWritable, IntWritable>{

        private IntWritable Time = new IntWritable(1);
        private IntWritable StateNum = new IntWritable(24);

        public void map(Object key, Text value, Context context
        ) throws IOException, InterruptedException {
            StringTokenizer lines = new StringTokenizer(value.toString(),"\n");
            int time = 24, stateNum = 0;
            while (lines.hasMoreTokens()) {
                time = 24;
                stateNum = 0;
                String line = lines.nextToken();
                String[] items = line.split(" ");

                // To extract Clock of specific log
                if ( items[1].length() == 21){
                    try{
                        time = Integer.parseInt(items[1].substring(13, 15));
                    }catch(Exception e){
                        System.out.println("Error when parsing time" + e.getMessage());
                        e.printStackTrace();
                        return ;
                    }
                }

                // To extract Number of Statement
                try{
                    stateNum = Integer.parseInt(items[items.length - 3]);
                    System.out.println(stateNum);
                }catch(Exception e){
                    System.out.println(" Error when get stateNum!" + e.getMessage());
                    e.printStackTrace();
                    return ;
                }

                //Debugging
                System.out.println(items[1].substring(13, 15) + "  ---   " + time);

                StateNum.set(stateNum);
                Time.set(time);
                context.write(StateNum, Time);
            }
        }
    }

    public static class IntSumReducer
            extends Reducer<IntWritable,IntWritable,IntWritable,IntWritable> {

        public void reduce(IntWritable key, Iterable<IntWritable> values,
                           Context context
        ) throws IOException, InterruptedException {
            /*
            int[] sum = new int[26];
            for ( int i = 0; i < 26; i ++)
                sum[i] = 0;
            for (IntWritable val : values) {
                sum[val.get()] += 1;
            }
            IntWritable[] Sum = new IntWritable[sum.length];
            for( int i = 0; i < sum.length; i ++)
                Sum[i] = new IntWritable(sum[i]);
            context.write(key, new IntArrayWritable(Sum));
            */
            int sum = 0;
            for (IntWritable val : values) {
                sum += val.get();
            }
            context.write(key,new IntWritable(sum));
        }
    }

    public static class IntArrayWritable extends ArrayWritable {
        public IntArrayWritable(IntWritable[] ints){
            super(IntWritable.class,ints);
        }

        @Override
        public IntWritable[] get(){
            return (IntWritable[])super.get();
        }

        @Override
        public String toString(){
            IntWritable[] values = get();
            String express = "";
            for( Integer i = 0; i < values.length; i ++){
                express += i.toString() + " " + values[i].toString() + "\n";
            }
            return express;
        }

        //@Override
        public String printStrings(){
            IntWritable[] values = get();
            String express = "";
            for( Integer i = 0; i < values.length; i ++){
                express += i.toString() + " " + values[i].toString() + "\n";
            }
            return express;
        }
    }

    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, "word count");
        job.setJarByClass(WordCount.class);
        job.setMapperClass(StateNumMapper.class);
        job.setCombinerClass(IntSumReducer.class);
        job.setReducerClass(IntSumReducer.class);
        job.setOutputKeyClass(IntWritable.class);
        job.setOutputValueClass(IntWritable.class);
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}
```

### Type MisMatch Error
We have to specific mapper export type like following:
```
job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(IntWritable.class);

        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntArrayWritable.class);
```
