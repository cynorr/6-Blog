title: Log_2015-11-26 -- Hadoop File Manage
date: 2015-11-26
category: Journal
toc: true
---
### 1.Creat, Copy, Rename, Delete File on HDFS
```Java
package com.hadooplearn.test;
import java.io.FileOutputStream;
import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
//学习HDFS的使用
public class HdfsLearn {
	//复制文件,从本地到HDFS
	public void copyFile(String src,String dst){
		Configuration conf = new Configuration();
		conf.set("mapred.job.tracker", "localhost:9001");  
        conf.set("fs.default.name", "hdfs://localhost:9000");
		FileSystem hdfs = null;
		try {
			hdfs = FileSystem.get(conf);
			Path srcPath = new Path(src);
			Path dstPath = new Path(dst);
			hdfs.copyFromLocalFile(srcPath, dstPath);
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} finally{
			if(hdfs != null){
				try {
					hdfs.close();
				} catch (IOException e) {
					// TODO Auto-generated catch block
					e.printStackTrace();
				}
			}
		}
	}

	//创建新文件
	public void createFile(String dst){
		Configuration conf = new Configuration();
		conf.set("mapred.job.tracker","localhost:9001");
		conf.set("fs.default.name","hdfs://localhost:9000");
		FileSystem fs = null;
		FSDataOutputStream out = null;
		try{
			String content = "hello hadoop";
			Path path = new Path(dst);
			fs = FileSystem.get(conf);
			out = fs.create(path);
			out.write(content.getBytes());
			out.flush();
		}catch(Exception ex){
			ex.printStackTrace();
		}finally{
			if(out != null){
				try {
					out.close();
				} catch (IOException e) {
					// TODO Auto-generated catch block
					e.printStackTrace();
				}
			}
			if(fs != null){
				try {
					fs.close();
				} catch (IOException e) {
					// TODO Auto-generated catch block
					e.printStackTrace();
				}
			}
		}
	}

	public void renameFile(String str,String dst){
		Configuration conf = new Configuration();
		conf.set("mapred.job.tracker","localhost:9001");
		conf.set("fs.default.name","hdfs://localhost:9000");
		FileSystem fs = null;
		try{
			fs = FileSystem.get(conf);
			Path srcPath = new Path(str);
			Path dstPath = new Path(dst);
			fs.rename(srcPath, dstPath);
		}catch(Exception ex){
			ex.printStackTrace();
		}finally{
			if(fs != null){
				try {
					fs.close();
				} catch (IOException e) {
					// TODO Auto-generated catch block
					e.printStackTrace();
				}
			}
		}
	}

	public void deleteFile(String src){
		Configuration conf = new Configuration();
		conf.set("mapred.job.tracker","localhost:9001");
		conf.set("fs.default.name","hdfs://localhost:9000");
		FileSystem fs = null;
		try{
			fs = FileSystem.get(conf);
			fs.delete(new Path(src));
		}catch(Exception ex){
			ex.printStackTrace();
		}finally{
			if(fs != null){
				try {
					fs.close();
				} catch (IOException e) {
					// TODO Auto-generated catch block
					e.printStackTrace();
				}
			}
		}
	}

	public static void main(String[] args){
		System.setProperty("HADOOP_USER_NAME", "pijing");
		String src = "/home/pijing/input/test1";
		String dst = "/";
		HdfsLearn learn = new HdfsLearn();
//		learn.copyFile(src, dst);
//		System.out.println("copy file from local file system to HDFS");
//		learn.createFile("/test2");
//		System.out.println("create file test2");
//		String org = "/test2";
//		String lasted = "/test3";
//		learn.renameFile(org, lasted);
//		System.out.println("rename file /test2 to /test3");
		learn.deleteFile("/test3");
		System.out.println("delete file /test3");
	}
}
```
