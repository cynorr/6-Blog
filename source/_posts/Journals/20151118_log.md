title: Log_2015-11-18 -- File and Dictionary Authority, Hadoop New/Old API
date: 2015-11-18
category: Journal
toc: true
---

### File and Dictionary Authority
1. chmod 只修改子目录
   如果只修改子目录（不包括文件）权限，举例：
   chmod 755 `find -type d`
   或者：
  find /目录 -type d -exec chmod 755 {} \;
  find /目录 -type f -exec chmod 644 {} \; （相反，只改文件）

```java
import java.io.IOException;
import java.util.StringTokenizer;


import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.ArrayWritable;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.Writable;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.RecordWriter;
import org.apache.hadoop.mapred.lib.MultipleOutputFormat;
import org.apache.hadoop.mapred.lib.MultipleTextOutputFormat;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.util.Progressable;

public class WordCount {

    public static class StateNumMapper
            extends Mapper<Object, Text, Text, IntArrayWritable> {

        private IntArrayWritable Time = new IntArrayWritable();
        private Text IPStr = new Text();

        public void map(Object key, Text value, Context context
        ) throws IOException, InterruptedException {
            StringTokenizer lines = new StringTokenizer(value.toString(),"\n");
            while (lines.hasMoreTokens()) {
                int time = 0;
                int stateNum = 0;
                String line = lines.nextToken();
                String[] items = line.split(" ");

                // To extract Clock of specific log
                if ( items[1].length() == 21){
                    try{
                        time = Integer.parseInt(items[1].substring(13, 15));
                    }catch(Exception e){
                        System.out.println("Error when parsing time" + e.getMessage());
                        e.printStackTrace();
                    }
                }

                // To extract Number of IP Address
                IPStr.set(items[0]);
                IntWritable [] timeArray = new IntWritable[1];
                timeArray[0] = new IntWritable(time);
                Time.set(timeArray);
                context.write(IPStr, Time);
            }
        }
    }


    public static class StateNumCombiner
            extends Reducer<Text,IntArrayWritable,Text,IntArrayWritable> {

        private IntArrayWritable IPAllHourStatis = new IntArrayWritable();
        private IntWritable [] IPAllHourStatisWritableArray = new IntWritable[26];

        public void reduce(Text key, Iterable<IntArrayWritable> values,
                           Context context ) throws IOException, InterruptedException {
            int stateNum;
            int[] IPAllHourStatisArray = new int[26];
            for ( int i = 0; i < 26; i ++)
                IPAllHourStatisArray[i] = 0;
            for (IntArrayWritable valArray : values){
                Writable[] valWritable = valArray.get();
                IntWritable tempIntWritable = (IntWritable)valWritable[0];
                stateNum = tempIntWritable.get();
                IPAllHourStatisArray[stateNum] ++;
            }

            for (int i = 0; i < 26; i++ )
                IPAllHourStatisWritableArray[i] = new IntWritable(IPAllHourStatisArray[i]);

            IPAllHourStatis.set(IPAllHourStatisWritableArray);
            context.write(null,IPAllHourStatis);
        }
    }

    public static class MultiOutPut extends MultipleOutputFormat<Text, IntArrayWritable> {

        private TextOutputFormat<Text, IntArrayWritable> outputer = null;
        protected RecordWriter<Text, IntArrayWritable>
            getBaseRecordWriter(FileSystem fs, JobConf job, String name, Progressable arg3)
                        throws IOException {
            if (outputer == null) {
                outputer = new TextOutputFormat<Text, IntArrayWritable>();
            }
            return outputer.getRecordWriter(fs, job, name, arg3);
        }

        protected String generateFileNameForKeyValue(Text key, IntArrayWritable value, String name){
            return key.toString();
        }
    }
/*
    public static class StateNumReducer
            extends Reducer<IntWritable,IntArrayWritable,Text,IntArrayWritable> {

        private IntArrayWritable SingleHourStatis = new IntArrayWritable();
        private IntWritable [] SingleHourStatisIntWritableArray = new IntWritable[3];

        public void reduce(IntWritable key, Iterable<IntArrayWritable> values,
                           Context context ) throws IOException, InterruptedException {
            int stateNum;
            int[] SingleHourStatisIntArray = new int[3];
            for ( int i = 0; i < 3; i ++)
                SingleHourStatisIntArray[i] = 0;
            for (IntArrayWritable valArray : values){
                Writable[] valWritable = valArray.get();
                for ( int i = 0; i < 3; i++){
                    IntWritable tempIntWritable = (IntWritable)valWritable[i];
                    stateNum = tempIntWritable.get();
                    SingleHourStatisIntArray[i] += stateNum;
                }
            }
            if ( key.get() != -1){

                for (int i = 0; i < 3; i++ )
                    SingleHourStatisIntWritableArray[i] = new IntWritable(SingleHourStatisIntArray[i]);

                SingleHourStatis.set(SingleHourStatisIntWritableArray);
                String keyStr = key.toString() + ":00-"+(key.get() + 1) + ":00";
                context.write(new Text(keyStr), SingleHourStatis);
            }else{
                String keyStr = "200:"+SingleHourStatisIntArray[0] + "\n" +
                        "404:" + SingleHourStatisIntArray[1] + "\n" +
                        "500:" + SingleHourStatisIntArray[2];
                context.write(new Text(keyStr), null);
            }
        }
    }
*/
    public static class IntArrayWritable
            extends ArrayWritable {
        public IntArrayWritable(){
            super(IntWritable.class);
        }

        public String toString(){
            String str = "";
            Writable[] values = get();
            IntWritable[] Values = new IntWritable[26];
            for (int i = 0; i < 24; i ++){
                Values[i] = (IntWritable)values[i];
                str += i + " " + Values[i].toString() + "\n";
            }

            return str;
        }
    }

    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        conf.set("mapreduce.output.textoutputformat.separator", " ");

        Job job = Job.getInstance(conf, "word count");
        job.setJarByClass(WordCount.class);

        job.setMapperClass(StateNumMapper.class);
        //job.setCombinerClass(StateNumCombiner.class);
        //job.setReducerClass(StateNumReducer.class);
        job.setReducerClass(StateNumCombiner.class);

        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(IntArrayWritable.class);

        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntArrayWritable.class);

        job.setOutputFormatClass(TextOutputFormat.class);


        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}
```
### Hadoop new api is incompatible with old api
New API : org.hadoop.mapreduce.*
Old API : org.hadoop.mapred.*
